{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Solving Tic-Tac-Toe with Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction \n",
    "\n",
    "Multiplayer games can be implemented as:\n",
    "1. Nondeterministic actions: The opponent is seen as part of an environment with nondeterministic actions. Non-determinism is the result of the unknown opponent's moves. \n",
    "2. Optimal Decisions: Minimax search (search complete game tree) and alpha-beta pruning.\n",
    "3. Heuristic Alpha-Beta Tree Search: Cut off tree search and use heuristic to estimate state value. \n",
    "4. __Monte Carlo Search:__ Simulate playouts to estimate state value. \n",
    "\n",
    "Here we will implement search for Tic-Tac-Toe (see [rules](https://en.wikipedia.org/wiki/Tic-tac-toe)). The game is a __zero-sum game__: Win by x results in +1, win by o in -1 and a tie has a value of 0. Max plays x and tries to maximize the outcome while Min plays o and tries to minimize the outcome.   \n",
    "\n",
    "We will implement\n",
    "* We enhance Pure Monte Carlo Search by using the upper confidence bound (UCB1) selection policy. That is, we use UCB1 to determine for which action to perform the next playout. This will allow the algorithm to focus on actions here it needs to collect more information. Note that complete Upper Confidence Bounds applied to Trees (UCT) creates a tree and the expand step in the code needs to be added. The tree branch for the chosen move is preserved and used for future moves."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The board\n",
    "\n",
    "I represent the board as a vector of length 9. The values are `' ', 'x', 'o'`.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def empty_board():\n",
    "    return [' '] * 9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some helper functions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# use higher resolution images in notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def show_board(board, help = True, dpi = 40, colors = {' ': 'white', 'x': 'red', 'o': 'black'}):\n",
    "    \"\"\"Show the tic-tac-toe-board. help adds the array index, dpi changes the sice and \n",
    "    colors sets the colors\"\"\"\n",
    "    \n",
    "    b = np.array(board).reshape((3,3))\n",
    "\n",
    "    with plt.rc_context({'figure.dpi': dpi}):\n",
    "        fig = plt.matshow(np.zeros((3, 3)), cmap = ListedColormap(['w']))\n",
    "    fig.axes.axis('off')\n",
    "    \n",
    "    plt.hlines([.5, 1.5], -.5, 2.5)\n",
    "    plt.vlines([.5, 1.5], -.5, 2.5)\n",
    "\n",
    "    for row in range(3):\n",
    "        for col in range(3):\n",
    "            plt.text(row, col, b[col, row], \n",
    "                 fontsize = 64, \n",
    "                 color = colors[b[col, row]],\n",
    "                 horizontalalignment = 'center',\n",
    "                 verticalalignment = 'center')\n",
    "        \n",
    "    if help:\n",
    "        for row in range(3):\n",
    "            for col in range(3):\n",
    "                plt.text(col, row - .35, col + 3 * row, \n",
    "                     fontsize = 12, \n",
    "                     color = 'gray',\n",
    "                     horizontalalignment = 'center',\n",
    "                     verticalalignment = 'center')\n",
    "        \n",
    "        \n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_win(board):\n",
    "    \"\"\"check the board and return one of x, o, d (draw), or n (for next move)\"\"\"\n",
    "    \n",
    "    board = np.array(board).reshape((3,3))\n",
    "    \n",
    "    diagonals = np.array([[board[i][i] for i in range(len(board))], \n",
    "                          [board[i][len(board)-i-1] for i in range(len(board))]])\n",
    "    \n",
    "    for a_board in [board, np.transpose(board), diagonals]:\n",
    "        for row in a_board:\n",
    "            if len(set(row)) == 1 and row[0] != ' ':\n",
    "                return row[0]\n",
    "    \n",
    "    # check for draw\n",
    "    if(np.sum(board == ' ') < 1):\n",
    "        return 'd'\n",
    "    \n",
    "    return 'n'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def actions(board):\n",
    "    \"\"\"return possible actions as a vector ot indices\"\"\"\n",
    "    return np.where(np.array(board) == ' ')[0].tolist()\n",
    "\n",
    "    # randomize the action order\n",
    "    #actions = np.where(np.array(board) == ' ')[0]\n",
    "    #np.random.shuffle(actions)\n",
    "    #return actions.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def result(state, player, action):\n",
    "    \"\"\"Add move to the board.\"\"\"\n",
    "    \n",
    "    state = state.copy()\n",
    "    state[action] = player\n",
    "  \n",
    "    return state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def other(player): \n",
    "    if player == 'x': return 'o'\n",
    "    else: return 'x'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def utility(state, player = 'x'):\n",
    "    \"\"\"check is a state is terminal and return the utility if it is. None means not a terminal mode.\"\"\"\n",
    "    goal = check_win(state)        \n",
    "    if goal == player: return +1         # win\n",
    "    if goal == 'd': return 0             # draw\n",
    "    if goal == other(player): return -1  # loss\n",
    "    return None                          # utility is not defined "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Monte Carlo Search with Upper Confidence Bound\n",
    "\n",
    "See AIMA page 163. \n",
    "\n",
    "We enhance pure Monte Carlo Search by using UCB1 as a __selection policy__. This can be seen as a \n",
    "restricted version of UTC: \n",
    "* Only build a tree of depth 1 and use the UBC1 selection policy.\n",
    "* Use a random playout policy.\n",
    "\n",
    "\n",
    "__Note on the playout policy:__ We use here a random playout policy, which ends up creating just a randomized search that works fine for this toy problem. For real applications you need to extend the code with a good __playout policy__ (e.g., manually created heuristics or a neural [network learned by self-play using reinforcement learning](https://towardsdatascience.com/how-to-teach-an-ai-to-play-games-deep-reinforcement-learning-28f9b920440a))."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulate playouts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def playout(state, action, player = 'x'):\n",
    "    \"\"\"Perfrom a random playout starting with the given action on the fiven board \n",
    "    and return the utility of the finished game.\"\"\"\n",
    "    state = result(state, player, action)\n",
    "    current_player = other(player)\n",
    "    \n",
    "    while(True):\n",
    "        # reached terminal state?\n",
    "        u = utility(state, player)\n",
    "        if u is not None: \n",
    "            return u\n",
    "        \n",
    "        # we use a random playout policy\n",
    "        a = np.random.choice(actions(state))\n",
    "        state = result(state, current_player, a)\n",
    "        #print(state)\n",
    "        \n",
    "        # switch between players\n",
    "        current_player = other(current_player)\n",
    "\n",
    "\n",
    "board = empty_board()\n",
    "print(playout(board, 0))\n",
    "print(playout(board, 0))\n",
    "print(playout(board, 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upper Confidence Bound Applied to Trees (Restricted to Depth 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "def UCT_depth1(board, N = 100, player = 'x'):\n",
    "    \"\"\"Upper Confidence bound applied to Trees for limited tree depth of 1. \n",
    "    Simulation budget is N playouts.\"\"\"\n",
    "    global DEBUG\n",
    "    \n",
    "    C = math.sqrt(2) # tradeoff constant\n",
    "    \n",
    "    # the tree is 1 action deep\n",
    "    acts = actions(board)\n",
    "    \n",
    "    u = [0] * len(acts) # total utility through actions\n",
    "    n = [0] * len(acts) # number of playouts through actions\n",
    "    n_parent = 0 # total playouts so far (i.e., number of playouts through parent)\n",
    "    \n",
    "    # make sure we try each action once\n",
    "    UCB1 = [+math.inf] * len(acts) \n",
    "    \n",
    "    for i in range(N):\n",
    "\n",
    "        # Select\n",
    "        action_id = UCB1.index(max(UCB1))\n",
    "    \n",
    "        # Expand\n",
    "        # UTC would expand the tree. We keep the tree at depth 1, essentially performing\n",
    "        # Pure Monte Carlo search with an added UCB1 selection policy. \n",
    "        \n",
    "        # Simulate\n",
    "        p = playout(board, acts[action_id], player = player)\n",
    "    \n",
    "        # Back-Propagate (i.e., update counts and UCB1)\n",
    "        u[action_id] += p\n",
    "        n[action_id] += 1\n",
    "        n_parent += 1\n",
    "        \n",
    "        for action_id in range(len(acts)):\n",
    "            if n[action_id] > 0:\n",
    "                UCB1[action_id] = u[action_id] / n[action_id] + C * math.sqrt(math.log(n_parent) / n[action_id])\n",
    "    \n",
    "    # return action with largest number of playouts \n",
    "    action = acts[n.index(max(n))]\n",
    "    \n",
    "    if DEBUG >= 1: \n",
    "        print(pd.DataFrame({'action':acts, \n",
    "                            'total utility':u, \n",
    "                            '# of playouts':n, \n",
    "                            'UCB1':UCB1}))\n",
    "        print()\n",
    "        print(f\"Best action: {action}\")\n",
    "    \n",
    "    \n",
    "    return action"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = empty_board()\n",
    "display(board)\n",
    "\n",
    "%timeit -n 1 -r 1 UCT_depth1(board, N = 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Some Tests\n",
    "\n",
    "### x is about to win (play 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%timeit -n1 -r1 UCT_depth1(board)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### o is about to win"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'o'\n",
    "board[1] = 'o'\n",
    "board[3] = 'o'\n",
    "board[4] = 'x'\n",
    "board[8] = 'x'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%timeit -n1 -r1 UCT_depth1(board, N = 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### x can draw if it chooses 7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'x'\n",
    "board[1] = 'o'\n",
    "board[2] = 'x'\n",
    "board[4] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "print()\n",
    "%timeit -n1 -r1 UCT_depth1(board, N = 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Empty board: Only a draw an be guaranteed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = empty_board() \n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "\n",
    "print()\n",
    "%timeit -n1 -r1 UCT_depth1(board, N = 100)\n",
    "%timeit -n1 -r1 UCT_depth1(board, N = 5000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A bad situation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = empty_board() \n",
    "board[0] = 'o'\n",
    "board[2] = 'x'\n",
    "board[8] = 'o'\n",
    "\n",
    "print(\"Board:\")\n",
    "show_board(board)\n",
    "\n",
    "\n",
    "print()\n",
    "display(UCT_depth1(board))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Note:__ It looks like random player o is very unlikely to block x and take advantage of the trap by playing the bottom left corner!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments\n",
    "\n",
    "\n",
    "### Baseline: Randomized Player\n",
    "\n",
    "A completely randomized player agent should be a weak baseline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_player(board, player = None):\n",
    "    \"\"\"Simple player that chooses a random empy square. player is unused\"\"\"\n",
    "    return np.random.choice(actions(board))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Environment\n",
    "\n",
    "Implement the environment that calls the agent. The percept is the board and the action is move."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEBUG = 1\n",
    "\n",
    "def switch_player(player, x, o):\n",
    "    if player == 'x':\n",
    "        return 'o', o\n",
    "    else:\n",
    "        return 'x', x\n",
    "\n",
    "def play(x, o, N = 100):\n",
    "    results = {'x': 0, 'o': 0, 'd': 0}\n",
    "    for i in range(N):\n",
    "        board = empty_board()\n",
    "        player, fun = 'x', x\n",
    "        \n",
    "        while True:\n",
    "            a = fun(board, player)\n",
    "            board = result(board, player, a)\n",
    "            \n",
    "            win = check_win(board)\n",
    "            if win != 'n':\n",
    "                if DEBUG >= 1: print(f\"{board} winner: {win}\")\n",
    "                results[win] += 1\n",
    "                break\n",
    "            \n",
    "            player, fun = switch_player(player, x, o)   \n",
    " \n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random vs. Random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "\n",
    "%timeit -n 1 -r 1 display(play(random_player, random_player))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pure Monte Carlo Search vs. Random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ucb1_10_player(board, player = 'x'):\n",
    "    action = UCT_depth1(board, N = 10, player = player)\n",
    "    return action\n",
    "\n",
    "def ucb1_100_player(board, player = 'x'):\n",
    "    action = UCT_depth1(board, N = 100, player = player)\n",
    "    return action"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "print(\"UCB1 (10) vs. random:\")\n",
    "%timeit -n1 -r1 display(play(ucb1_10_player, random_player))\n",
    "\n",
    "print()\n",
    "print(\"random vs. UCB1 (10):\")\n",
    "%timeit -n1 -r1 display(play(random_player, ucb1_10_player))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "print(\"UCB1 (100) vs. random:\")\n",
    "%timeit -n 1 -r 1 display(play(ucb1_100_player, random_player))\n",
    "\n",
    "print()\n",
    "print(\"random vs. UCB1 (100):\")\n",
    "%timeit -n 1 -r 1 display(play(random_player, ucb1_100_player))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEBUG = 0\n",
    "print(\"UCB1 (100) vs. UCB1 (10):\")\n",
    "%timeit -n 1 -r 1 display(play(ucb1_100_player, ucb1_10_player))\n",
    "\n",
    "print()\n",
    "print(\"UCB1 (10) vs. UCB1 (100):\")\n",
    "%timeit -n 1 -r 1 display(play(ucb1_10_player, ucb1_100_player))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}